{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a4abe8",
   "metadata": {},
   "source": [
    "# NK Cell Cytotoxicity Analysis Pipeline\n",
    "\n",
    "### üìì Fluorescence Time-lapse Imaging ‚Äî Tutorial\n",
    "\n",
    "This tutorial demonstrates an automated imaging analysis pipeline for quantifying NK cell cytotoxic behaviour at the single-cell level. It processes fluorescence time-lapse microscopy data through key steps including:\n",
    "\n",
    "- Image import and visualisation\n",
    "- Channel unmixing and preprocessing\n",
    "- Cell segmentation using Cellpose\n",
    "- Tracking with BayesianTracker\n",
    "- Functional analysis and visual outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6ea6d7",
   "metadata": {},
   "source": [
    "**Environment & Visualisation Setup**\n",
    "\n",
    "This section configures the Python environment by importing all required libraries and setting up visualisation styles for consistent plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ab979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import textwrap\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter, FFMpegWriter\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pims\n",
    "import napari\n",
    "from cellpose import models\n",
    "\n",
    "from skimage.color import label2rgb\n",
    "from skimage.exposure import adjust_gamma\n",
    "from skimage.measure import regionprops\n",
    "from skimage.morphology import disk, dilation\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "sys.path.append('./Cyto-Visual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['animation.embed_limit'] = 1000\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"mathtext.fontset\": \"stix\",\n",
    "    \"font.family\": \"STIXGeneral\",\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"savefig.format\": \"pdf\",\n",
    "    \"legend.edgecolor\": \"0.0\",\n",
    "    \"legend.framealpha\": 1.0,\n",
    "})\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6874a0c",
   "metadata": {},
   "source": [
    "# $\\Alpha$. Import the imaging file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bcb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getIN import load_tiff_sequence\n",
    "\n",
    "# define your folder containing the imaging data here:\n",
    "folder_path = \"/Users/marsian/PhD_LifeSciRes/Image_Python/Cathal_Data/good_3/test\"\n",
    "\n",
    "# Import the imaging\n",
    "ioi_files, ioi_files_name = load_tiff_sequence(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2541cb6",
   "metadata": {},
   "source": [
    "**Use Napari for Visualisation**\n",
    "\n",
    "<p align=\"left\">\n",
    "  <img src=\"https://napari.org/stable/_static/logo.png\" alt=\"napari logo\" width=\"40\" style=\"vertical-align:middle; margin-right:10px;\">\n",
    "  <code>Napari</code> is a fast, interactive, and user-friendly viewer optimised for large, multi-dimensional image data. Compared to <code>matplotlib</code>-based animations in Jupyter notebooks, Napari provides a smoother, more flexible experience for visualising time-lapse microscopy data interactively.\n",
    "</p>\n",
    "\n",
    "> üìå Use <code>napari.run()</code> to launch the GUI interactively from a script or notebook.\n",
    "\n",
    "---\n",
    "\n",
    "While Napari is ideal for interactive exploration, `matplotlib` is still useful when you need to **export animations** as GIF or MP4 files.  \n",
    "We provide a helper function to generate and save publication-ready animations using `matplotlib.animation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 0 # Define the file sequence that you would like to visualise\n",
    "viewer = napari.Viewer()\n",
    "max_list = [0.4, 0.6, 0.8]\n",
    "Colormap = ['I Orange', 'I Forest', 'I Bordeaux']\n",
    "for ch in range(ioi_files[file].shape[3]-1):\n",
    "    viewer.add_image(\n",
    "        ioi_files[file][:,:,:,ch],\n",
    "        name = f'file_{file}_post_ch_{ch}',\n",
    "        blending='minimum', \n",
    "        colormap=Colormap[ch],\n",
    "        contrast_limits=(0, max_list[ch]*np.max(ioi_files[file][:,:,:,ch]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed11807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Matplotlib to visualise\n",
    "from visua import mat_visua\n",
    "\n",
    "# Just display\n",
    "html = mat_visua(ioi_files)\n",
    "display(html)\n",
    "\n",
    "# Display and save as MP4\n",
    "# mat_visua(ioi_files, save=True, filename=\"NK_animation\", format=\"mp4\")\n",
    "\n",
    "# Save as GIF\n",
    "# mat_visua(ioi_files, save=True, filename=\"NK_animation\", format=\"gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f17f73",
   "metadata": {},
   "source": [
    "# $\\Beta$. Pre-processing\n",
    "\n",
    "\n",
    "Use the `pre_processing()` function to apply a customisable sequence of image processing steps to 4D fluorescence time-lapse stacks `(T, Y, X, C)`.\n",
    "\n",
    "---\n",
    "\n",
    "**Default usage**  \n",
    "This runs `[\"trim\", \"unmix\", \"normalize\"]` by default:\n",
    "\n",
    "```python\n",
    "processed = pre_processing(ioi_files)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Custom pipeline**  \n",
    "Define your own ordered steps:\n",
    "\n",
    "```python\n",
    "steps = [\"background\", \"unmix\", \"normalize\", \"gamma\"]\n",
    "processed = pre_processing(\n",
    "    ioi_files,\n",
    "    time_interval=100,\n",
    "    processing_steps=steps,\n",
    "    gamma=1.5\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Use a custom unmixing matrix:**\n",
    "\n",
    "```python\n",
    "custom_M = np.array([\n",
    "    [0.55, 0.05, 0.20],\n",
    "    [0.01, 0.70, 0.02],\n",
    "    [0.08, 0.00, 0.45]\n",
    "])\n",
    "processed = pre_processing(ioi_files, mixing_matrix=custom_M)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Parameters summary**\n",
    "\n",
    "| Parameter         | Description                                      |\n",
    "|------------------|--------------------------------------------------|\n",
    "| `ioi_files`       | Dict of 4D stacks `(T, Y, X, C)`                 |\n",
    "| `time_interval`   | Trim to max number of frames                    |\n",
    "| `processing_steps`| List of steps: `[\"trim\", \"background\", \"threshold\", \"unmix\", \"normalize\", \"gamma\"]` |\n",
    "| `mixing_matrix`   | `\"default\"` or custom `np.ndarray` (C √ó C)       |\n",
    "| `gamma`           | Gamma value (e.g. 1.5) if `\"gamma\"` in steps     |\n",
    "\n",
    "---\n",
    "\n",
    "**Output**  \n",
    "Returns a dictionary of processed stacks with the same keys and shapes as `ioi_files`.\n",
    "\n",
    "```python\n",
    "processed[\"sample1\"].shape  # (T, Y, X, C)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepo import *\n",
    "\n",
    "custom_matrix = np.array([\n",
    "    [0.55, 0.05, 0.20],\n",
    "    [0.01, 0.70, 0.02],\n",
    "    [0.08, 0.00, 0.45]\n",
    "])\n",
    "\n",
    "ioi_processing = pre_processing(\n",
    "    ioi_files,\n",
    "    time_interval=120,\n",
    "    processing_steps=[\"trim\", \"unmix\", \"normalize\"],\n",
    "    mixing_matrix=custom_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 0\n",
    "viewer = napari.Viewer()\n",
    "Colormap = ['I Blue', 'I Forest', 'I Bordeaux']\n",
    "for ch in range(ioi_processing[file].shape[3]):\n",
    "    viewer.add_image(\n",
    "        ioi_processing[file][:,:,:,ch],\n",
    "        name = f'post_ch_{ch}',\n",
    "        blending='minimum', \n",
    "        colormap=Colormap[ch]\n",
    "    )\n",
    "\n",
    "# for ch in range(ioi_processing[file].shape[3]):\n",
    "#     viewer.add_image(\n",
    "#         ioi_files[file][:time_interval,:,:,ch],\n",
    "#         name = f'raw_ch_{ch}',\n",
    "#         blending='minimum', \n",
    "#         colormap=Colormap[ch]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0533d",
   "metadata": {},
   "source": [
    "# $\\Gamma$. Segmenting and Merging the Masks. \n",
    "# Extracting the regional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seg import *  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69780d2d",
   "metadata": {},
   "source": [
    "**Cellpose Segmentation Parameters**\n",
    "\n",
    "| Parameter           | Description                                                    | Typical Range     | Default | Effect            |\n",
    "|---------------------|----------------------------------------------------------------|--------------------|---------|----------------------------------------|\n",
    "| `flow_threshold`    |  the maximum allowed error of the flows for each mask     | 0.0 ‚Äì 1.0          | 0.4     |Increase this threshold if cellpose is not returning as many ROIs as you‚Äôd expect. Similarly, decrease this threshold if cellpose is returning too many ill-shaped ROIs  |\n",
    "| `cellprob_threshold`| it is used to run dynamics and determine ROIs               | -6.0 ‚Äì 6.0         | 0.0     | Decrease this threshold if cellpose is not returning as many ROIs as you‚Äôd expect. Similarly, increase this threshold if cellpose is returning too ROIs particularly from dim areas.         |\n",
    "\n",
    "Use these to balance sensitivity and specificity depending on signal quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c4ace",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è **Warning**: `run_cellpose_segmentation()` can be **very slow** when processing many timepoints or large image stacks.\n",
    "\n",
    "To speed things up, we provide a **Snakemake-based pipeline** for batch segmentation on **HPC clusters** ‚Äî see the [GitHub repository](https://github.com/ElephesSung/CytotoxicVision) for details.\n",
    "\n",
    "For this tutorial, we **re-import pre-segmented mask files** to save time.  \n",
    "You're welcome to run the full segmentation yourself and export your own results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_masks = run_cellpose_segmentation(\n",
    "    ioi_processing,\n",
    "    diameter=None,\n",
    "    channels=[0, 0],\n",
    "    flow_thresholds=[0.4, 0.4, 0.6],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90a969",
   "metadata": {},
   "source": [
    "you can use this code to export your masks data (```ioi_masks```) to a pkl file.\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "file_name = \"ioi_masks_Les_gamma2.pkl\"  # Name of the saved file\n",
    "file_path = os.path.join(folder_path, file_name)  # Combine folder path with filename\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Save dictionary to a file\n",
    "with open(file_path, \"wb\") as file:\n",
    "    pickle.dump(ioi_masks, file)\n",
    "print(f\"Dictionary saved successfully to {file_path}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can re-import your saved pkl file here\n",
    "file_path = os.path.join(folder_path, \"ioi_masks_Les.pkl\")\n",
    "with open(file_path, \"rb\") as file:\n",
    "    ioi_masks = pickle.load(file)\n",
    "print(\"Dictionary reloaded successfully from:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd229f51",
   "metadata": {},
   "source": [
    "**Remove Small Masks**\n",
    "\n",
    "Utility functions are provided to:\n",
    "\n",
    "- Plot mask area distributions by file and channel.\n",
    "- Remove small masks likely caused by segmentation noise.\n",
    "\n",
    "You can define a minimum area threshold per channel or apply a global threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask_area_distributions(\n",
    "    ioi_masks,\n",
    "    file_names=ioi_files_name,\n",
    "    channel_labels=[\"NK cells\", \"721.221 cells\", \"Death reporter\"],\n",
    "    bins=50,\n",
    "    xlim=(0, 175),\n",
    "    # save_path=\"mask_area_distribution.svg\"  # Save as SVG\n",
    ")\n",
    "\n",
    "cleaned_ioi_masks = clean_masks(ioi_masks, area_threshold=40, channels=[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af667aef",
   "metadata": {},
   "source": [
    "**Region Extraction & Mask Merging**\n",
    "\n",
    "This function merges selected mask channels and extracts per-object region properties (e.g. area, centroid, intensity) for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af40bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_region, ioi_masks_merge = region_info(\n",
    "    ioi_masks=cleaned_ioi_masks,\n",
    "    ioi_processing=ioi_processing,\n",
    "    ioi_files=ioi_files,\n",
    "    merge_channels=(1, 2),\n",
    "    merge_mode='OR',\n",
    "    iou_threshold=0.04,\n",
    "    extract_channels=(0, 1, 2),\n",
    "    region_features=(\"area\", \"coords\", \"centroid\", \"label\"),\n",
    "    include_intensity=True,\n",
    "    include_raw_intensity=True,\n",
    "    time_trim=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a01fb9",
   "metadata": {},
   "source": [
    "You can extract fluorescence intensities from the merged 721.221 tumour and apoptotic reporter channels to identify two distinct clusters, corresponding to live and dead cells.\n",
    "This feature will be used in the following code, after tracking, to classify cell states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo_ANA import plot_joint_fluo\n",
    "plot_joint_fluo(\n",
    "    ioi_region[1]['ch12'],\n",
    "    file_name=ioi_files_name[1],\n",
    "    mode=\"linear\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d1073b",
   "metadata": {},
   "source": [
    "# $\\Delta$ Cell migration tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c85081e",
   "metadata": {},
   "source": [
    "<p align=\"left\">\n",
    "  <img src=\"https://camo.githubusercontent.com/778aad38a3c4e6c07eb70f1de8e596d12d09b36b6e67e6b49df00bf67b0a68ed/68747470733a2f2f62747261636b2e72656164746865646f63732e696f2f656e2f6c61746573742f5f696d616765732f62747261636b5f6c6f676f2e706e67\" alt=\"btrack logo\" width=\"100\" style=\"vertical-align:middle; margin-right:10px;\">\n",
    "  We use <code>btrack</code>, the Bayesian tracker, to track cell migration.\n",
    "  For more information and optimisation tips, see the \n",
    "  <a href=\"https://github.com/quantumjot/btrack\" target=\"_blank\">GitHub repo</a> and the \n",
    "  <a href=\"https://btrack.readthedocs.io/en/latest/\" target=\"_blank\">official documentation</a>.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a22892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import track\n",
    "from track import *\n",
    "\n",
    "feature_dict = {\n",
    "    'ch0': ['area'],\n",
    "    'ch12': ['area']\n",
    "}\n",
    "\n",
    "ioi_tracking, ioi_napari_tracks = run_btrack(\n",
    "    ioi_region=ioi_region,\n",
    "    ioi_masks=ioi_masks,\n",
    "    feature_dictionary=feature_dict,\n",
    "    ioi_processing=ioi_processing,\n",
    "    ioi_files=ioi_files,\n",
    "    config_path=\"./cell_config.json\"\n",
    ")\n",
    "\n",
    "#os.path.join(folder_path, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "file = 0\n",
    "trim = 50\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "pixel_size_xy = 810.44 / 512\n",
    "scale = (1, pixel_size_xy, pixel_size_xy)\n",
    "\n",
    "channel_colormaps = ['I Blue', 'I Forest', 'I Bordeaux']\n",
    "mask_colormap = 'gist_earth'\n",
    "\n",
    "for ch in range(ioi_processing[file].shape[-1]):\n",
    "    viewer.add_image(\n",
    "        ioi_processing[file][0:trim, :, :, ch],\n",
    "        name=f'post_ch_{ch}',\n",
    "        blending='minimum',\n",
    "        colormap=channel_colormaps[ch],\n",
    "        scale=scale,\n",
    "    )\n",
    "\n",
    "for ch in range(ioi_masks_merge[file].shape[-1]):\n",
    "    viewer.add_image(\n",
    "        ioi_masks_merge[file][0:trim, :, :, ch],\n",
    "        name=f'seg_ch_{ch}',\n",
    "        blending='additive',\n",
    "        colormap=mask_colormap,\n",
    "        scale=scale,\n",
    "    )\n",
    "\n",
    "track_labels = {\n",
    "    'ch0': 'Tracks_NK',\n",
    "    'ch12': 'Tracks_TUDR',\n",
    "}\n",
    "\n",
    "for label_key, display_name in track_labels.items():\n",
    "    if label_key in ioi_napari_tracks[file]:\n",
    "        viewer.add_tracks(\n",
    "            ioi_napari_tracks[file][label_key],\n",
    "            name=display_name,\n",
    "            blending='translucent',\n",
    "            visible=True,\n",
    "            colormap=mask_colormap,\n",
    "            tail_length=8,\n",
    "            scale=scale,\n",
    "        )\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = \"um\"\n",
    "viewer.scale_bar.position = \"bottom_right\"\n",
    "viewer.scale_bar.font_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d927528a",
   "metadata": {},
   "source": [
    "# $\\Delta$. Temporal Evolution of the fluorescence intensities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f2b22",
   "metadata": {},
   "source": [
    "### $\\delta$-i. Classifying Target Cell Status: From Clustering to Thresholding\n",
    "\n",
    "We initially used unsupervised clustering (Ward or GMM) on fluorescence features‚ÄîCalcium Green (channel 1) and TO-PRO-3 (channel 2)‚Äîto distinguish live and dead target cells. In this scheme, live targets exhibit high Calcium Green and low TO-PRO-3, while dead targets show the opposite pattern.\n",
    "\n",
    "However, the subset of cells with high signals in both channels (‚Äúdouble positive‚Äù), which also corresponded to dead cells. To address this, we adopted a threshold-based classification, segmenting cells into four groups based on marginal thresholds for each channel. Only the (high Calcium, low TO-PRO-3) group is considered truly alive; all other combinations, including double positives, are classified as dead. This approach provides a more accurate and biologically meaningful distinction between live and dead target cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo_ANA import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_test = classify_cell_states(\n",
    "    ioi_tracking,\n",
    "    ioi_files_name=ioi_files_name,\n",
    "    cluster_labels=[\"live targets\", \"dead targets\"] ,\n",
    "    # use_gmm=True,\n",
    "    use_raw=True,\n",
    "    use_log=True,\n",
    "    point_size=12,\n",
    "    # n_clusters=4,\n",
    "    xlim=(5.1, 7.6),  \n",
    "    ylim=(5.4, 6.2)   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default: GMM thresholding, log1p, raw intensities, default group-to-cluster mapping\n",
    "ioi_tracking = threshold_cell_states(\n",
    "    ioi_tracking,\n",
    "    ioi_files_name=ioi_files_name,\n",
    "    threshold_method=\"gmm\",  # \"gmm\" or \"kde\", \"otsu\", \"yen\", \"li\"\n",
    "    use_log=True,\n",
    "    use_raw=True,\n",
    "    cluster_labels=[\"Alive\", \"Dead\"],\n",
    "    point_size=12,\n",
    "    group_to_cluster={(1,0): 0, (0,0): 1, (0,1): 1, (1,1): 1},  # (1,0) is alive, others dead\n",
    "    xlim=(5.1, 7.6),\n",
    "    ylim=(5.4, 6.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempo_ANA\n",
    "from tempo_ANA import *\n",
    "\n",
    "ioi_tracking = threshold_cell_states_3(\n",
    "    ioi_tracking,\n",
    "    ioi_files_name=ioi_files_name,\n",
    "    cluster_labels=[\"live 721.221 cells\", \"dead 722.221 cells\"],\n",
    "    palette={\"live 721.221 cells\": \"seagreen\", \"dead 722.221 cells\": \"salmon\"},\n",
    "    xlabel=\"log(Calcium Green intensity)\",\n",
    "    ylabel=\"log(TO-PRO-3 intensity)\",\n",
    "    axis_label_fontsize=18,\n",
    "    # legend_title=\"Cell Status\",\n",
    "    legend_fontsize=14,\n",
    "    hist_bins=100,\n",
    "    save_path=\"./\",\n",
    "    save_format=\"pdf\"  # \"svg\" or \"pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81164e60",
   "metadata": {},
   "source": [
    "### $\\delta$-ii. Temporal evolution of fluorescence intensity \n",
    "We visualise individual cell tracks based on their temporal fluorescence intensity in two channels:\n",
    "\n",
    "- **Channel 1**: 721.221 (green) ‚Äî marker for live cells  \n",
    "- **Channel 2**: TO-PRO-3 (red) ‚Äî marker for cell death\n",
    "\n",
    "Each row corresponds to a cell behaviour category:\n",
    "1. **Always Live** (consistently low TO-PRO-3, high 721.221)\n",
    "2. **Always Dead** (high TO-PRO-3, low 721.221)\n",
    "3. **Live ‚Üí Dead Transition** (initially live, then death marker rises)\n",
    "\n",
    "Each subplot shows a single cell‚Äôs intensity over time (`Frames`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dba458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all_TempoFluo(ioi_tracking[0]['ch12'], min_track_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the tracking dataframe for one sample (e.g., file 0)\n",
    "df = ioi_tracking[1]['ch12']\n",
    "\n",
    "# Categorise cells by their temporal cell status transition\n",
    "always_0, always_1, transition_0_to_1 = categorise(df, min_track_length=25)\n",
    "\n",
    "# Plot temporal fluorescence profiles for each category\n",
    "plot_ex_TempoFluo(\n",
    "    df,\n",
    "    always_0,\n",
    "    always_1,\n",
    "    transition_0_to_1,\n",
    "    num_cols=7,  # You can change this to however many columns you want\n",
    "    figsize=(16, 6),\n",
    "    ch1_label='721.221',\n",
    "    ch2_label='TO-PRO-3',\n",
    "    ch1_color='seagreen',\n",
    "    ch2_color='salmon',\n",
    "    show_ids=False,\n",
    "    ylim=(0, 1600),\n",
    "    save_path=\"temporal_profiles.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bddd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barrels(\n",
    "    df,\n",
    "    always_0,\n",
    "    always_1,\n",
    "    transition_0_to_1,\n",
    "    ch1_label='Calcein Green AM (mean)',\n",
    "    ch2_label='TO-PRO-3 (mean)',\n",
    "    xlims=[(0, 60), (0, 60), (-30, 25)],\n",
    "    titles = [None, None, None]\n",
    "    # save_path=\"barrels_plot.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the sample index and target cell ID\n",
    "sample_index = 0\n",
    "target_cell_id = 12\n",
    "\n",
    "import importlib\n",
    "importlib.reload(tempo_ANA)\n",
    "from tempo_ANA import animate_scProfile\n",
    "interactive_html = animate_scProfile(\n",
    "    ioi_tracking=ioi_tracking,         # List of tracking DataFrames\n",
    "    ioi_files=ioi_files,               # List of 5D image arrays (T, H, W, C)\n",
    "    file=sample_index,                 # Select the specific sample\n",
    "    target_Tu_id=target_cell_id,       # Particle ID to animate\n",
    "    time_interval=60,                  # Number of frames to animate\n",
    "    crop_size=100,                     # Size of cropped view around cell\n",
    "    fig_width=15,                      # Width of the output figure\n",
    "    fig_height=6,                      # Height of the output figure\n",
    "    profile_time_extend=5,            # Extend profile range on both sides\n",
    "    save_gif_path=\"./\",       # Uncomment to save animation as GIF\n",
    "    ch1_label='Calcein Green AM',\n",
    "    ch2_label='TO-PRO-3'\n",
    ")\n",
    "\n",
    "# Display in notebook\n",
    "display(interactive_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7ad2b",
   "metadata": {},
   "source": [
    "# $\\Epsilon$. Contact Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55da8a",
   "metadata": {},
   "source": [
    "\n",
    "This section outlines a pipeline to detect and summarise NK cell contacts with target cells (e.g., tumour cells), based on mask overlap and distance criteria across time-lapse imaging data.\n",
    "\n",
    "> ‚ö†Ô∏è **Note:** The current algorithm is not yet validated against manual ground truth annotations. Experimental verification will be conducted in future steps.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_contacts(ioi_tracking, normal_TUDR_list, distance_threshold=30, min_track_length=25):\n",
    "    from skimage.morphology import disk, dilation\n",
    "    import numpy as np\n",
    "    import json\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    def enlarge_coordinates(coords, radius):\n",
    "        max_y = max(coord[0] for coord in coords) + radius + 10\n",
    "        max_x = max(coord[1] for coord in coords) + radius + 10\n",
    "        binary_mask = np.zeros((int(max_y), int(max_x)), dtype=bool)\n",
    "        for y, x in coords:\n",
    "            binary_mask[int(y), int(x)] = 1\n",
    "        footprint = disk(radius)\n",
    "        dilated_mask = dilation(binary_mask, footprint)\n",
    "        return [tuple(p) for p in np.argwhere(dilated_mask)]\n",
    "\n",
    "    def has_intersection(coords1, coords2):\n",
    "        return int(bool(set(coords1) & set(coords2)))\n",
    "\n",
    "    for _, image_key in tqdm(enumerate(ioi_tracking), desc='files', total=len(ioi_tracking)):\n",
    "        df_TUDR = ioi_tracking[image_key]['ch12']\n",
    "        df_TUDR = df_TUDR[df_TUDR['id'].isin(normal_TUDR_list)]\n",
    "\n",
    "        df_NK = ioi_tracking[image_key]['ch0']\n",
    "        df_NK = df_NK.groupby('id').filter(lambda sub: len(sub) >= min_track_length)\n",
    "        NK_ids = df_NK['id'].unique()\n",
    "\n",
    "        for nk_id in tqdm(NK_ids, desc='NK_cell_id', leave=False):\n",
    "            nk_df = df_NK[df_NK['id'] == nk_id]\n",
    "            for t in nk_df['t'].unique():\n",
    "                nk_frame = nk_df[nk_df['t'] == t]\n",
    "                nk_coords = [tuple(c) for c in np.array(nk_frame['coords'].iloc[0])]\n",
    "                nk_y, nk_x = nk_frame['y'].iloc[0], nk_frame['x'].iloc[0]\n",
    "\n",
    "                TUDR_frame = df_TUDR[df_TUDR['t'] == t]\n",
    "                contact_no = 0\n",
    "                contacted_ids = []\n",
    "\n",
    "                for _, tu in TUDR_frame.iterrows():\n",
    "                    tu_y, tu_x = tu['y'], tu['x']\n",
    "                    tu_coords = [tuple(p) for p in np.array(tu['coords'])]\n",
    "                    dist = np.hypot(nk_y - tu_y, nk_x - tu_x)\n",
    "                    if dist <= distance_threshold:\n",
    "                        intersects = has_intersection(\n",
    "                            enlarge_coordinates(tu_coords, 1),\n",
    "                            enlarge_coordinates(nk_coords, 1)\n",
    "                        )\n",
    "                        if intersects:\n",
    "                            contact_no += 1\n",
    "                            contacted_ids.append(tu['id'])\n",
    "\n",
    "                            # Ensure NK_incontact_id exists and update\n",
    "                            if 'NK_incontact_id' not in ioi_tracking[image_key]['ch12'].columns:\n",
    "                                ioi_tracking[image_key]['ch12']['NK_incontact_id'] = \"\"\n",
    "                            existing = ioi_tracking[image_key]['ch12'].loc[\n",
    "                                (ioi_tracking[image_key]['ch12']['id'] == tu['id']) &\n",
    "                                (ioi_tracking[image_key]['ch12']['t'] == t), 'NK_incontact_id'\n",
    "                            ].values[0]\n",
    "                            try:\n",
    "                                current_ids = json.loads(existing) if existing else []\n",
    "                                if isinstance(current_ids, int):\n",
    "                                    current_ids = [current_ids]\n",
    "                                current_ids.append(int(nk_id))\n",
    "                            except json.JSONDecodeError:\n",
    "                                current_ids = [int(nk_id)]\n",
    "                            ioi_tracking[image_key]['ch12'].loc[\n",
    "                                (ioi_tracking[image_key]['ch12']['id'] == tu['id']) &\n",
    "                                (ioi_tracking[image_key]['ch12']['t'] == t), 'NK_incontact_id'\n",
    "                            ] = json.dumps(current_ids)\n",
    "\n",
    "                # Save contact info to NK cell\n",
    "                ioi_tracking[image_key]['ch0'].loc[\n",
    "                    (ioi_tracking[image_key]['ch0']['id'] == nk_id) &\n",
    "                    (ioi_tracking[image_key]['ch0']['t'] == t), 'contact'\n",
    "                ] = contact_no\n",
    "                ioi_tracking[image_key]['ch0'].loc[\n",
    "                    (ioi_tracking[image_key]['ch0']['id'] == nk_id) &\n",
    "                    (ioi_tracking[image_key]['ch0']['t'] == t), 'TU_contact'\n",
    "                ] = json.dumps(contacted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_contacts(ioi_tracking, NK_channel='ch0', min_track_length=25):\n",
    "    import numpy as np\n",
    "    import json\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "    stats_data = {}\n",
    "\n",
    "    def count_contact_events(binary_list):\n",
    "        binary = np.array(binary_list)\n",
    "        changes = np.diff(binary, prepend=0)\n",
    "        starts = np.where(changes == 1)[0]\n",
    "        ends = np.where(changes == -1)[0]\n",
    "        if len(ends) < len(starts):\n",
    "            ends = np.append(ends, len(binary))\n",
    "        return len(starts), (ends - starts).tolist()\n",
    "\n",
    "    for _, image_key in tqdm(enumerate(ioi_tracking), desc='File', total=len(ioi_tracking)):\n",
    "        stats_data[image_key] = {'NK': {}}\n",
    "        df = ioi_tracking[image_key][NK_channel]\n",
    "        df = df.groupby('id').filter(lambda x: len(x) >= min_track_length)\n",
    "        for pid in tqdm(df['id'].unique(), desc='NK Particle', leave=False):\n",
    "            stats_data[image_key]['NK'][pid] = {}\n",
    "            df_pid = df[df['id'] == pid].sort_values('t')\n",
    "\n",
    "            contact_seq = [\n",
    "                json.loads(row['TU_contact']) if isinstance(row['TU_contact'], str) else row['TU_contact']\n",
    "                for _, row in df_pid.iterrows()\n",
    "            ]\n",
    "            stats_data[image_key]['NK'][pid]['contact_sequence'] = contact_seq\n",
    "\n",
    "            all_tu = sorted(set(num for s in contact_seq if isinstance(s, (list, tuple)) for num in s))\n",
    "            stats_data[image_key]['NK'][pid]['TU_unique_id'] = all_tu\n",
    "\n",
    "            total_contacts = 0\n",
    "            durations = []\n",
    "            for tu in all_tu:\n",
    "                binary = [1 if tu in s else 0 for s in contact_seq]\n",
    "                num, dur = count_contact_events(binary)\n",
    "                total_contacts += num\n",
    "                durations += dur\n",
    "\n",
    "            stats_data[image_key]['NK'][pid]['total_contacts'] = total_contacts\n",
    "            stats_data[image_key]['NK'][pid]['duration_list'] = durations\n",
    "\n",
    "    return stats_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Detect contacts\n",
    "detect_contacts(\n",
    "    ioi_tracking=ioi_tracking,\n",
    "    normal_TUDR_list=always_0 + always_1 + transition_0_to_1,\n",
    "    distance_threshold=30,\n",
    "    min_track_length=25\n",
    ")\n",
    "\n",
    "# 2. Summarise contact statistics\n",
    "contact_stats = summarise_contacts(\n",
    "    ioi_tracking=ioi_tracking,\n",
    "    NK_channel='ch0',           # default\n",
    "    min_track_length=25         # default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19565666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_nk_contact_duration_distribution(ioi_file_stats_data, \n",
    "                                          binwidth=1, \n",
    "                                          contact_xlim=(0, 60), \n",
    "                                          figsize_per_file=(5, 4),\n",
    "                                          save_path=None, \n",
    "                                          save_format=None):\n",
    "    \"\"\"\n",
    "    Plot NK cell contact duration distributions across files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ioi_file_stats_data : dict\n",
    "        Output from summarise_contacts, structured by file -> 'NK' -> particle_id.\n",
    "    binwidth : int\n",
    "        Bin width for histogram bars.\n",
    "    contact_xlim : tuple\n",
    "        (min, max) range for x-axis (contact durations).\n",
    "    figsize_per_file : tuple\n",
    "        Size of each subplot (width, height).\n",
    "    save_path : str or None\n",
    "        Directory to save the figure. If None, shows plot instead.\n",
    "    save_format : str or None\n",
    "        If provided ('svg' or 'pdf'), figure will be saved in that format.\n",
    "    \"\"\"\n",
    "\n",
    "    num_files = len(ioi_file_stats_data)\n",
    "    fig, axes = plt.subplots(\n",
    "        num_files, 1, \n",
    "        # figsize=(figsize_per_file[0], figsize_per_file[1] * num_files),\n",
    "        figsize =(10, 6),\n",
    "        sharex=False,\n",
    "        dpi = 300\n",
    "    )\n",
    "\n",
    "    if num_files == 1:\n",
    "        axes = [axes]  # ensure it's iterable\n",
    "\n",
    "    for file_idx, ax in enumerate(axes):\n",
    "        durations = [\n",
    "            duration\n",
    "            for particle_id in ioi_file_stats_data[file_idx]['NK']\n",
    "            for duration in ioi_file_stats_data[file_idx]['NK'][particle_id]['duration_list']\n",
    "        ]\n",
    "\n",
    "        if not durations:\n",
    "            ax.text(0.5, 0.5, \"No contacts\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        sns.histplot(\n",
    "            durations, \n",
    "            binwidth=binwidth,\n",
    "            ax=ax,\n",
    "            kde=False,\n",
    "            stat='count',\n",
    "            color=\"salmon\", \n",
    "            edgecolor=\"black\"\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"File {file_idx} ‚Äì NK Contact Duration\", fontsize=11, fontweight=\"bold\")\n",
    "        ax.set_ylabel(\"Frequency\", fontsize=9)\n",
    "        ax.set_xlim(*contact_xlim)\n",
    "\n",
    "        # Ticks\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "        ax.xaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "        ax.tick_params(axis='x', which='both', labelsize=7)\n",
    "        ax.tick_params(axis='y', which='both', labelsize=7)\n",
    "\n",
    "        # Grid\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Final shared X label\n",
    "    axes[-1].set_xlabel(\"Contact Duration (frames)\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path and save_format:\n",
    "        if save_format.lower() not in ['svg', 'pdf']:\n",
    "            raise ValueError(\"save_format must be either 'svg' or 'pdf'\")\n",
    "        output_file = f\"{save_path}/nk_contact_durations.{save_format.lower()}\"\n",
    "        plt.savefig(output_file, bbox_inches='tight')\n",
    "        print(f\"Figure saved to {output_file}\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nk_contact_duration_distribution(\n",
    "    ioi_file_stats_data=contact_stats,\n",
    "    binwidth=1,\n",
    "    contact_xlim=(0, 60),\n",
    "    save_path=None,             # Set path to save, e.g., './figures'\n",
    "    save_format=None            # Use 'svg' or 'pdf' to save\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
